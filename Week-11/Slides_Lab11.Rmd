---
title: "Statistics in R"
author: "Cornelius Senf and Dirk Pflugmacher"
output:
  ioslides_presentation:
    smaller: yes
    widescreen: yes
  beamer_presentation: default
  slidy_presentation: default
subtitle: Quantitative Methods - Lab Session 11
header-includes: \usepackage{amsmath}
---

<style type="text/css">
slide.backdrop {
  background: none !important;
  background-color: white !important;
}
</style>

```{r echo=FALSE, hide=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
```

## Today's session:

- Cluster analysis (kmeans and hierarchical)
- Reading raster files
- Principal component analysis


# Cluster analysis

## Cluster analysis

Cluster analysis assignes each data point to one of k clusters, thereby maximmizing the between-cluster variance and minimizing the within-cluster variance.

There are two principal types of cluster algorithms: partionating algorithms (e.g. kmeans) and hierarchical algorithms.

## kmeans

A kmeans cluster analysis can be performed using the `kmeans()` function:

```{r}
data(iris)

iris_kmeans <- kmeans(x = iris[, c(1:4)], centers = 3)
```

## kmeans

```{r, echo=FALSE}
iris_kmeans
```

## kmeans

We can plot the cluster solution using ggplot:

```{r}
iris$cluster3 <- iris_kmeans$cluster

p <- ggplot(iris, aes(Sepal.Length, y = Sepal.Width, col = factor(cluster3))) +
  geom_point()
```

## kmeans

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5, fig.width=10, fig.align='center'}
print(p)
```

## kmeans

And compare it to the acutal species classification:

```{r}
table(iris$cluster3, iris$Species)
```

## kmeans

More/less clusters lead to different solutions:

```{r}
iris$cluster2 <- kmeans(x = iris[, c(1:4)], centers = 2)$cluster
iris$cluster4 <- kmeans(x = iris[, c(1:4)], centers = 4)$cluster
iris$cluster5 <- kmeans(x = iris[, c(1:4)], centers = 5)$cluster
iris$cluster6 <- kmeans(x = iris[, c(1:4)], centers = 6)$cluster

p <- iris %>%
  gather(key = k, value = cluster, -(Sepal.Length:Species)) %>%
  ggplot(., aes(Sepal.Length, y = Sepal.Width, col = factor(cluster))) +
  geom_point() +
  facet_wrap(~k, ncol = 6)
```

## kmeans

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5, fig.width=10, fig.align='center'}
print(p)
```

## Hierarchical clustering

Hierarchical clustering can be performed using the `hclust()` function. However, we first need to calcuate the distances (similarities) between each data point pair:

```{r}
dist <- dist(iris[, 1:4])
```

There are several methods for calculating the distance (e.g., euclidean, manhatten, ...), see `?dist()`. With the distance matrix we can hierarchically cluster all data points:

```{r}
iris_hc <- hclust(dist)
```

And plot i using the `ggdrndro` package:

```{r}
library(ggdendro)

p <- ggdendrogram(iris_hc)
```

See https://cran.r-project.org/web/packages/ggdendro/vignettes/ggdendro.html for further information.

## Hierarchical clustering

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5, fig.width=10, fig.align='center'}
print(p)
```

# Reading raster files

## Reading raster files

For todays exercise we are going to use data that is stored in a raster stack, that is a stack of gridded rasters with matching spatial resolution and extent.

Reading a raster stack can be done using the `stack()` function in the raster package:

```{r, warning=FALSE, message=FALSE}
library(raster)

clim <- stack("Data/climate.envi")
```

Raster stacks can be of any format (geoTiff, ENVI, grid, bsq, etc.) and with or without spatial reference. For reading a single raster instead of a stack, you can use the `raster()` function.

## Reading raster files

```{r}
clim

names(clim) <- c("Tmin", "Tmean", "Tmax", "Precip")
```

## Reading raster files

Plotting the raster is easily achieved by the `plot()` command. However, you have to select a layer for plotting:

```{r, eval=FALSE}
plot(clim, y = 1)
```

## Reading raster files

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5, fig.width=8, fig.align='center'}
plot(clim, y = 1)
```

## Reading raster files

Rasters can have millions of pixels, which can make computations very slow. To deal with this issue, we are going to sample 10,000 pixels from the raster:

```{r}
clim_samp <- sampleRandom(clim, size = 10000)
clim_samp <- as.data.frame(clim_samp) # sampleRandom returns a matrix

clim_samp[1:5, ]
```

## Reading raster files

```{r, message=FALSE, warning=FALSE}
library(GGally)

p <- clim_samp %>%
  sample_n(., size = 100) %>%
  ggpairs(.)
```

## Reading raster files

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=6, fig.align='center'}
print(p)
```

# Principle Component Analysis

## Principle Component Analysis

There are two functions in R for performaing a PCA: `princomp()` and `prcomp()`. While the former function calculates the eigenvalue on the correlation/covariance matrix using the function `eigen()`, the latter function uses singular value decomposition, which numerically more stable. We here are going to use `prcomp()`.

## Principle Component Analysis

```{r}
pca <- prcomp(clim_samp, scale. = TRUE)
```

You should set the `scale.` argument to `TRUE`, to scale the data matrix to unit variances. The default is `scale. = FALSE`. You can also use `scale()` to standardize the original data matrix and then enter the standardized data matrix to prcomp.

## Principle Component Analysis

The `prcomp` object stores the rotations (eigenvectors) which define the contribution of each variable to a component:

```{r}
pca$rotation
```

## Principle Component Analysis

The eigenvalues are also stored in the `prcomp` object:

```{r}
pca$sdev
```

And can be easily translated into variance explained:

```{r}
var_exp <- data.frame(pc = 1:4,
                      var_exp = pca$sdev^2 / sum(pca$sdev^2))

var_exp$var_exp_cumsum <- cumsum(var_exp$var_exp)

p <- ggplot(var_exp) +
  geom_bar(aes(x = pc, y = var_exp), stat = "identity") +
  geom_line(aes(x = pc, y = var_exp_cumsum))
```

## Principle Component Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=5, fig.width=5, fig.align='center'}
print(p)
```

## Principle Component Analysis

We can now apply the PCA transformation to the whole raster stack:

```{r}
clim_pca <- raster::predict(clim, pca, index = 1:4)
```

## Principle Component Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=10, fig.align='center', results='asis'}
plot(subset(clim_pca, 1))
```

## Principle Component Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=10, fig.align='center', results='asis'}
plot(subset(clim_pca, 2))
```

## Principle Component Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=10, fig.align='center', results='asis'}
plot(subset(clim_pca, 3))
```

## Principle Component Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=10, fig.align='center', results='asis'}
plot(subset(clim_pca, 4))
```

## Now the magic!

Let's combine PCA and kmeans:

```{r, results='hide', fig.show='hide'}
pca_values <- as.data.frame(clim_pca)
pca_kmeans <- kmeans(pca_values[, 1:3], centers = 5)
kmean_raster <- raster(clim_pca)
values(kmean_raster) <- pca_kmeans$cluster
plot(kmean_raster)
```

## Now the magic!

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=6, fig.width=10, fig.align='center', results='asis'}
plot(kmean_raster)
```